# ğŸ““ Jupyter Notebook Guide
# HÆ°á»›ng Dáº«n Notebook Jupyter

> **Cell-by-Cell Documentation for brave9.ipynb**

---

## ğŸ“– Language Preference / Chá»n NgÃ´n Ngá»¯

- **[ENGLISH](#english-version)** - Main documentation (scroll down for full English version)
- **[TIáº¾NG VIá»†T](#vietnamese-version)** - TÃ i liá»‡u tiáº¿ng Viá»‡t (cuá»™n xuá»‘ng Ä‘á»ƒ xem phiÃªn báº£n tiáº¿ng Viá»‡t Ä‘áº§y Ä‘á»§)

---

# ENGLISH VERSION

## ğŸ““ Jupyter Notebook Guide

### File: `brave9.ipynb`

Complete machine learning workflow with 37 cells organized in 10 main sections.

---

## ğŸ“‹ Notebook Sections

## ğŸ“‹ Notebook Sections

### 1. Introduction
- Project title and objectives
- Dataset overview
- Navigation guide

### 2. Libraries
- `pandas`, `numpy` - Data manipulation
- `scikit-learn` - ML algorithms
- `xgboost` - Gradient boosting
- `matplotlib`, `seaborn` - Visualization
- All plots inline with `random_state=42`

### 3. Task Description
- **Goal**: Predict math scores
- **Dataset**: 1,000 students, 8 features
- **Target**: Math score (0-100)
- **Factors**: Gender, race, parental education, lunch type, test prep

### 4. Data Loading
```python
df = pd.read_csv("StudentsPerformance.csv")
```
- Loads 1,000 records
- Shows first 5 rows + data info
- **Result**: 0 missing values (clean data)

### 5. Exploratory Data Analysis
- **Missing Values**: None âœ“
- **Statistics**: Mean, std, quartiles
- **Distributions**: Histograms for all scores
- **Correlations**: Reading-Writing (0.954), Math-Reading (0.818)
- **Feature Relationships**: Boxplots by demographic groups
- **Key Finding**: SES (lunch) shows largest effect (10+ point gap)

### 6. Data Preprocessing
- Separate target (y) and features (X)
- One-hot encoding for categorical variables
- 5 features â†’ 11 features after encoding
- Train-test split: 80-20, random_state=42

### 7. Evaluation Function
- Calculate RMSE, MAE, RÂ² metrics
- Helper for model comparison

### 8. Linear Regression
- **Purpose**: Baseline model
- **Results**: RÂ²=0.23, RMSE=13.05, MAE=10.24
- **Interpretation**: Explains 23% of variance

### 9. XGBoost Regression
- **Configuration**: 100 trees, max_depth=5, learning_rate=0.1
- **Results**: RÂ²=0.26, RMSE=12.26, MAE=9.87
- **Improvement**: 13% better RÂ², 6.1% better RMSE
- **Interpretation**: Explains 26% of variance

### 10. Model Comparison
- Side-by-side metrics comparison
- Bar chart visualization
- **Winner**: XGBoost on all metrics

### 11. Feature Importance
- Extract importance from XGBoost
- Top 5 predictors:
  1. lunch (34.2%)
  2. parental_education (21.5%)
  3. test_prep (18.9%)
  4. race/ethnicity (1.9%)
  5. gender (1.1%)
- Horizontal bar chart visualization

### 12. Conclusions
- Summary of findings
- Policy recommendations (3 tiers)
- Limitations and future work

---

## ğŸ”„ Execution Flow

**Important**: Run cells in order (1â†’37)
- Variables depend on previous cells
- Don't skip or reorder

**Runtime**: ~30-45 seconds for full notebook

**Output Types**:
- Console: Statistics, metrics
- Tables: DataFrames displayed
- Charts: 5+ visualizations (EDA, comparison, importance)
- Warnings: Safe to ignore (deprecations)

---

## ğŸ’¾ Key Variables

### After Preprocessing
- `X`: Features (1000 Ã— 11)
- `y`: Target (1000,)
- `X_train`, `X_test`: Train/test split (800/200)
- `y_train`, `y_test`: Target split

### After Modeling
- `lr_model`: Linear Regression object
- `xgb_model`: XGBoost object
- `y_pred_lr`, `y_pred_xgb`: Predictions
- `lr_metrics`, `xgb_metrics`: Results dictionaries

### After Feature Importance
- `feature_importance`: DataFrame with rankings

---

## ğŸ¨ Visualizations Generated

1. **Histograms** - Score distributions
2. **Heatmap** - Correlation matrix
3. **Boxplots** - Features vs math score
4. **Bar chart** - Model comparison
5. **Bar chart** - Feature importance

---

## ğŸ› ï¸ Useful Code Snippets

### Get metrics
```python
print(f"XGBoost RÂ²: {xgb_metrics['R2']:.4f}")
print(f"RMSE: {xgb_metrics['RMSE']:.2f}")
```

### Top features
```python
print(feature_importance.head(3))
```

### Make prediction
```python
new_data = X_test.iloc[[0]]
pred = xgb_model.predict(new_data)
```

### Save model
```python
import joblib
joblib.dump(xgb_model, 'model.pkl')
```

---

## âš ï¸ Important Notes

**Data**:
- Never modify original CSV
- All transformations in notebook
- Safe to re-run anytime

**Reproducibility**:
- `random_state=42` everywhere
- Same results on re-runs
- Notebook is deterministic

**Dependencies**:
- Requires `requirements.txt` packages
- Python 3.8-3.10 recommended
- 2GB RAM minimum

---

## â“ Troubleshooting

| Problem | Solution |
|---------|----------|
| Module not found | Run cell 4 again, check requirements |
| Data not loading | Verify CSV in SOURCE/ folder |
| Charts not showing | Run `%matplotlib inline` in cell 4 |
| Memory error | Restart kernel, check system RAM |

---

**Version**: 1.0  
**Last Updated**: November 2025  
**Status**: âœ… Production Ready  
**Author**: BÃ¹i Quang Chiáº¿n

---

---

# VIETNAMESE VERSION

# ğŸ““ HÆ°á»›ng Dáº«n Notebook Jupyter

## File: `brave9.ipynb`

Quy trÃ¬nh há»c mÃ¡y hoÃ n chá»‰nh vá»›i 37 cells Ä‘Æ°á»£c tá»• chá»©c trong 10 pháº§n chÃ­nh.

---

## ğŸ“‹ CÃ¡c Pháº§n cá»§a Notebook

### 1. Giá»›i Thiá»‡u (Cells 1-3)
- TiÃªu Ä‘á» vÃ  má»¥c tiÃªu dá»± Ã¡n
- Tá»•ng quan bá»™ dá»¯ liá»‡u
- HÆ°á»›ng dáº«n Ä‘iá»u hÆ°á»›ng

### 2. ThÆ° Viá»‡n (Cell 4)
- `pandas`, `numpy` - Thao tÃ¡c dá»¯ liá»‡u
- `scikit-learn` - CÃ¡c thuáº­t toÃ¡n ML
- `xgboost` - Gradient boosting
- `matplotlib`, `seaborn` - Trá»±c quan hÃ³a
- Táº¥t cáº£ cÃ¡c plot inline vá»›i `random_state=42`

### 3. MÃ´ Táº£ Nhiá»‡m Vá»¥ (Cells 5-9)
- **Má»¥c tiÃªu**: Dá»± Ä‘oÃ¡n Ä‘iá»ƒm toÃ¡n
- **Bá»™ dá»¯ liá»‡u**: 1.000 há»c sinh, 8 Ä‘áº·c trÆ°ng
- **Biáº¿n má»¥c tiÃªu**: Äiá»ƒm toÃ¡n (0-100)
- **Yáº¿u tá»‘**: Giá»›i tÃ­nh, chá»§ng tá»™c, trÃ¬nh Ä‘á»™ cha máº¹, loáº¡i bá»¯a trÆ°a, luyá»‡n thi

### 4. Táº£i Dá»¯ Liá»‡u (Cells 10-11)
```python
df = pd.read_csv("StudentsPerformance.csv")
```
- Táº£i 1.000 báº£n ghi
- Hiá»ƒn thá»‹ 5 hÃ ng Ä‘áº§u + thÃ´ng tin dá»¯ liá»‡u
- **Káº¿t quáº£**: 0 giÃ¡ trá»‹ thiáº¿u (dá»¯ liá»‡u sáº¡ch)

### 5. PhÃ¢n TÃ­ch KhÃ¡m PhÃ¡ Dá»¯ Liá»‡u (Cells 12-19)
- **GiÃ¡ Trá»‹ Thiáº¿u**: KhÃ´ng cÃ³ âœ“
- **Thá»‘ng KÃª**: Trung bÃ¬nh, Ä‘á»™ lá»‡ch chuáº©n, tá»© phÃ¢n vá»‹
- **PhÃ¢n Phá»‘i**: Biá»ƒu Ä‘á»“ cho táº¥t cáº£ cÃ¡c Ä‘iá»ƒm
- **TÆ°Æ¡ng Quan**: Äá»c-Viáº¿t (0.954), ToÃ¡n-Äá»c (0.818)
- **Má»‘i Quan Há»‡ Äáº·c TrÆ°ng**: Boxplots theo nhÃ³m nhÃ¢n kháº©u há»c
- **PhÃ¡t Hiá»‡n ChÃ­nh**: KXH (bá»¯a trÆ°a) cho tháº¥y áº£nh hÆ°á»Ÿng lá»›n nháº¥t (chÃªnh lá»‡ch 10+ Ä‘iá»ƒm)

### 6. Tiá»n Xá»­ LÃ½ Dá»¯ Liá»‡u (Cells 20-25)
- TÃ¡ch biáº¿n má»¥c tiÃªu (y) vÃ  Ä‘áº·c trÆ°ng (X)
- MÃ£ hÃ³a one-hot cho cÃ¡c biáº¿n phÃ¢n loáº¡i
- 5 Ä‘áº·c trÆ°ng â†’ 11 Ä‘áº·c trÆ°ng sau mÃ£ hÃ³a
- Chia train-test: 80-20, random_state=42

### 7. HÃ m ÄÃ¡nh GiÃ¡ (Cell 26)
- TÃ­nh toÃ¡n chá»‰ sá»‘ RMSE, MAE, RÂ²
- Trá»£ giÃºp so sÃ¡nh mÃ´ hÃ¬nh

### 8. Há»“i Quy Tuyáº¿n TÃ­nh (Cells 27-29)
- **Má»¥c Ä‘Ã­ch**: MÃ´ hÃ¬nh cÆ¡ sá»Ÿ
- **Káº¿t quáº£**: RÂ²=0.23, RMSE=13.05, MAE=10.24
- **Diá»…n giáº£i**: Giáº£i thÃ­ch 23% phÆ°Æ¡ng sai

### 9. Há»“i Quy XGBoost (Cells 30-32)
- **Cáº¥u hÃ¬nh**: 100 cÃ¢y, max_depth=5, learning_rate=0.1
- **Káº¿t quáº£**: RÂ²=0.26, RMSE=12.26, MAE=9.87
- **Cáº£i Thiá»‡n**: RÂ² tá»‘t hÆ¡n 13%, RMSE tá»‘t hÆ¡n 6,1%
- **Diá»…n giáº£i**: Giáº£i thÃ­ch 26% phÆ°Æ¡ng sai

### 10. So SÃ¡nh MÃ´ HÃ¬nh (Cell 33)
- So sÃ¡nh chá»‰ sá»‘ song song
- Trá»±c quan hÃ³a biá»ƒu Ä‘á»“ cá»™t
- **NgÆ°á»i Chiáº¿n Tháº¯ng**: XGBoost á»Ÿ táº¥t cáº£ chá»‰ sá»‘

### 11. Äá»™ Quan Trá»ng Äáº·c TrÆ°ng (Cell 34)
- TrÃ­ch xuáº¥t Ä‘á»™ quan trá»ng tá»« XGBoost
- 5 yáº¿u tá»‘ dá»± bÃ¡o hÃ ng Ä‘áº§u:
  1. lunch (34.2%)
  2. parental_education (21.5%)
  3. test_prep (18.9%)
  4. race/ethnicity (1.9%)
  5. gender (1.1%)
- Trá»±c quan hÃ³a biá»ƒu Ä‘á»“ cá»™t ngang

### 12. Káº¿t Luáº­n (Cell 37)
- TÃ³m táº¯t cÃ¡c phÃ¡t hiá»‡n
- Khuyáº¿n nghá»‹ chÃ­nh sÃ¡ch (3 cáº¥p)
- Háº¡n cháº¿ vÃ  hÆ°á»›ng phÃ¡t triá»ƒn tÆ°Æ¡ng lai

---

## ğŸ”„ Luá»“ng Thá»±c Thi

**Quan Trá»ng**: Cháº¡y cÃ¡c cells theo thá»© tá»± (1â†’37)
- CÃ¡c biáº¿n phá»¥ thuá»™c vÃ o cÃ¡c cells trÆ°á»›c Ä‘Ã³
- KhÃ´ng Ä‘Æ°á»£c bá» qua hoáº·c sáº¯p xáº¿p láº¡i

**Thá»i Gian Cháº¡y**: ~30-45 giÃ¢y cho toÃ n bá»™ notebook

**Loáº¡i Äáº§u Ra**:
- Console: Thá»‘ng kÃª, chá»‰ sá»‘
- Báº£ng: DataFrames Ä‘Æ°á»£c hiá»ƒn thá»‹
- Biá»ƒu Ä‘á»“: 5+ trá»±c quan hÃ³a (EDA, so sÃ¡nh, Ä‘á»™ quan trá»ng)
- Cáº£nh bÃ¡o: An toÃ n Ä‘á»ƒ bá» qua (khÃ´ng dÃ¹ng ná»¯a)

---

## ğŸ’¾ CÃ¡c Biáº¿n ChÃ­nh

### Sau Tiá»n Xá»­ LÃ½
- `X`: Äáº·c trÆ°ng (1000 Ã— 11)
- `y`: Biáº¿n má»¥c tiÃªu (1000,)
- `X_train`, `X_test`: Chia train/test (800/200)
- `y_train`, `y_test`: Chia biáº¿n má»¥c tiÃªu

### Sau MÃ´ HÃ¬nh HÃ³a
- `lr_model`: Äá»‘i tÆ°á»£ng Há»“i Quy Tuyáº¿n TÃ­nh
- `xgb_model`: Äá»‘i tÆ°á»£ng XGBoost
- `y_pred_lr`, `y_pred_xgb`: Dá»± Ä‘oÃ¡n
- `lr_metrics`, `xgb_metrics`: Tá»« Ä‘iá»ƒn káº¿t quáº£

### Sau PhÃ¢n TÃ­ch Äá»™ Quan Trá»ng
- `feature_importance`: DataFrame vá»›i xáº¿p háº¡ng

---

## ğŸ¨ Trá»±c Quan HÃ³a ÄÆ°á»£c Táº¡o

1. **Biá»ƒu Ä‘á»“ Histogram** - PhÃ¢n phá»‘i Ä‘iá»ƒm
2. **Heatmap** - Ma tráº­n tÆ°Æ¡ng quan
3. **Boxplots** - Äáº·c trÆ°ng vs Ä‘iá»ƒm toÃ¡n
4. **Biá»ƒu Ä‘á»“ Cá»™t** - So sÃ¡nh mÃ´ hÃ¬nh
5. **Biá»ƒu Ä‘á»“ Cá»™t** - Äá»™ quan trá»ng Ä‘áº·c trÆ°ng

---

## ğŸ› ï¸ CÃ¡c Äoáº¡n MÃ£ Há»¯u Ãch

### Láº¥y chá»‰ sá»‘
```python
print(f"XGBoost RÂ²: {xgb_metrics['R2']:.4f}")
print(f"RMSE: {xgb_metrics['RMSE']:.2f}")
```

### CÃ¡c Ä‘áº·c trÆ°ng hÃ ng Ä‘áº§u
```python
print(feature_importance.head(3))
```

### ÄÆ°a ra dá»± Ä‘oÃ¡n
```python
new_data = X_test.iloc[[0]]
pred = xgb_model.predict(new_data)
```

### LÆ°u mÃ´ hÃ¬nh
```python
import joblib
joblib.dump(xgb_model, 'model.pkl')
```

---

## âš ï¸ CÃ¡c Ghi ChÃº Quan Trá»ng

**Dá»¯ Liá»‡u**:
- KhÃ´ng bao giá» sá»­a Ä‘á»•i CSV gá»‘c
- Táº¥t cáº£ cÃ¡c biáº¿n Ä‘á»•i trong notebook
- An toÃ n Ä‘á»ƒ cháº¡y láº¡i báº¥t ká»³ lÃºc nÃ o

**TÃ¡i Láº­p**:
- `random_state=42` á»Ÿ má»i nÆ¡i
- Káº¿t quáº£ giá»‘ng nhau khi cháº¡y láº¡i
- Notebook lÃ  xÃ¡c Ä‘á»‹nh

**ThÆ° Viá»‡n Phá»¥ Thuá»™c**:
- YÃªu cáº§u cÃ¡c gÃ³i trong `requirements.txt`
- Python 3.8-3.10 Ä‘Æ°á»£c khuyáº¿n cÃ¡o
- Tá»‘i thiá»ƒu 2GB RAM

---

## â“ Kháº¯c Phá»¥c Sá»± Cá»‘

| Váº¥n Äá» | Giáº£i PhÃ¡p |
|--------|----------|
| KhÃ´ng tÃ¬m tháº¥y mÃ´-Ä‘un | Cháº¡y cell 4 láº¡i, kiá»ƒm tra requirements |
| Dá»¯ liá»‡u khÃ´ng táº£i | XÃ¡c minh CSV trong thÆ° má»¥c SOURCE/ |
| Biá»ƒu Ä‘á»“ khÃ´ng hiá»ƒn thá»‹ | Cháº¡y `%matplotlib inline` trong cell 4 |
| Lá»—i bá»™ nhá»› | Khá»Ÿi Ä‘á»™ng láº¡i kernel, kiá»ƒm tra RAM há»‡ thá»‘ng |

---

**PhiÃªn Báº£n**: 1.0  
**Cáº­p Nháº­t Láº§n Cuá»‘i**: ThÃ¡ng 11 nÄƒm 2025  
**Tráº¡ng ThÃ¡i**: âœ… Sáºµn SÃ ng Sáº£n Xuáº¥t  
**TÃ¡c Giáº£**: BÃ¹i Quang Chiáº¿n