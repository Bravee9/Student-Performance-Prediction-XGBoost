# ğŸ““ Jupyter Notebook Guide

## File: `brave9.ipynb`

Complete machine learning workflow with 37 cells organized in 10 main sections.

Quy trÃ¬nh há»c mÃ¡y hoÃ n chá»‰nh vá»›i 37 cells Ä‘Æ°á»£c tá»• chá»©c trong 10 pháº§n chÃ­nh.

---

## ğŸ“‹ Notebook Sections / CÃ¡c Pháº§n cá»§a Notebook

### 1. Introduction (Cells 1-3) / Giá»›i Thiá»‡u (Cells 1-3)
- Project title and objectives / TiÃªu Ä‘á» vÃ  má»¥c tiÃªu dá»± Ã¡n
- Dataset overview / Tá»•ng quan bá»™ dá»¯ liá»‡u
- Navigation guide / HÆ°á»›ng dáº«n Ä‘iá»u hÆ°á»›ng

### 2. Libraries (Cell 4) / ThÆ° Viá»‡n (Cell 4)
- `pandas`, `numpy` - Data manipulation / Thao tÃ¡c dá»¯ liá»‡u
- `scikit-learn` - ML algorithms / CÃ¡c thuáº­t toÃ¡n ML
- `xgboost` - Gradient boosting / Gradient boosting
- `matplotlib`, `seaborn` - Visualization / Trá»±c quan hÃ³a
- All plots inline with `random_state=42` / Táº¥t cáº£ cÃ¡c plot inline vá»›i `random_state=42`

### 3. Task Description (Cells 5-9) / MÃ´ Táº£ Nhiá»‡m Vá»¥ (Cells 5-9)
- **Goal / Má»¥c tiÃªu**: Predict math scores / Dá»± Ä‘oÃ¡n Ä‘iá»ƒm toÃ¡n
- **Dataset / Bá»™ dá»¯ liá»‡u**: 1,000 students / há»c sinh, 8 features / Ä‘áº·c trÆ°ng
- **Target / Biáº¿n má»¥c tiÃªu**: Math score / Äiá»ƒm toÃ¡n (0-100)
- **Factors / Yáº¿u tá»‘**: Gender / giá»›i tÃ­nh, race / chá»§ng tá»™c, parental education / trÃ¬nh Ä‘á»™ cha máº¹, lunch type / loáº¡i bá»¯a trÆ°a, test prep / luyá»‡n thi

### 4. Data Loading (Cells 10-11) / Táº£i Dá»¯ Liá»‡u (Cells 10-11)
```python
df = pd.read_csv("StudentsPerformance.csv")
```
- Loads 1,000 records / Táº£i 1.000 báº£n ghi
- Shows first 5 rows + data info / Hiá»ƒn thá»‹ 5 hÃ ng Ä‘áº§u + thÃ´ng tin dá»¯ liá»‡u
- **Result / Káº¿t quáº£**: 0 missing values (clean data) / 0 giÃ¡ trá»‹ thiáº¿u (dá»¯ liá»‡u sáº¡ch)

### 5. Exploratory Data Analysis (Cells 12-19) / PhÃ¢n TÃ­ch KhÃ¡m PhÃ¡ Dá»¯ Liá»‡u (Cells 12-19)
- **Missing Values / GiÃ¡ Trá»‹ Thiáº¿u**: None âœ“
- **Statistics / Thá»‘ng KÃª**: Mean, std, quartiles / Trung bÃ¬nh, Ä‘á»™ lá»‡ch chuáº©n, tá»© phÃ¢n vá»‹
- **Distributions / PhÃ¢n Phá»‘i**: Histograms for all scores / Biá»ƒu Ä‘á»“ cho táº¥t cáº£ cÃ¡c Ä‘iá»ƒm
- **Correlations / TÆ°Æ¡ng Quan**: Reading-Writing (0.954), Math-Reading (0.818) / Äá»c-Viáº¿t (0.954), ToÃ¡n-Äá»c (0.818)
- **Feature Relationships / Má»‘i Quan Há»‡ Äáº·c TrÆ°ng**: Boxplots by demographic groups / Boxplots theo nhÃ³m nhÃ¢n kháº©u há»c
- **Key Finding / PhÃ¡t Hiá»‡n ChÃ­nh**: SES (lunch) shows largest effect (10+ point gap) / KXH (bá»¯a trÆ°a) cho tháº¥y áº£nh hÆ°á»Ÿng lá»›n nháº¥t (chÃªnh lá»‡ch 10+ Ä‘iá»ƒm)

### 6. Data Preprocessing (Cells 20-25) / Tiá»n Xá»­ LÃ½ Dá»¯ Liá»‡u (Cells 20-25)
- Separate target (y) and features (X) / TÃ¡ch biáº¿n má»¥c tiÃªu (y) vÃ  Ä‘áº·c trÆ°ng (X)
- One-hot encoding for categorical variables / MÃ£ hÃ³a one-hot cho cÃ¡c biáº¿n phÃ¢n loáº¡i
- 5 features â†’ 11 features after encoding / 5 Ä‘áº·c trÆ°ng â†’ 11 Ä‘áº·c trÆ°ng sau mÃ£ hÃ³a
- Train-test split: 80-20, random_state=42 / Chia train-test: 80-20, random_state=42

### 7. Evaluation Function (Cell 26) / HÃ m ÄÃ¡nh GiÃ¡ (Cell 26)
- Calculate RMSE, MAE, RÂ² metrics / TÃ­nh toÃ¡n chá»‰ sá»‘ RMSE, MAE, RÂ²
- Helper for model comparison / Trá»£ giÃºp so sÃ¡nh mÃ´ hÃ¬nh

### 8. Linear Regression (Cells 27-29) / Há»“i Quy Tuyáº¿n TÃ­nh (Cells 27-29)
- **Purpose / Má»¥c Ä‘Ã­ch**: Baseline model / MÃ´ hÃ¬nh cÆ¡ sá»Ÿ
- **Results / Káº¿t quáº£**: RÂ²=0.23, RMSE=13.05, MAE=10.24
- **Interpretation / Diá»…n giáº£i**: Explains 23% of variance / Giáº£i thÃ­ch 23% phÆ°Æ¡ng sai

### 9. XGBoost Regression (Cells 30-32) / Há»“i Quy XGBoost (Cells 30-32)
- **Configuration / Cáº¥u hÃ¬nh**: 100 trees, max_depth=5, learning_rate=0.1
- **Results / Káº¿t quáº£**: RÂ²=0.26, RMSE=12.26, MAE=9.87
- **Improvement / Cáº£i Thiá»‡n**: 13% better RÂ², 6.1% better RMSE / RÂ² tá»‘t hÆ¡n 13%, RMSE tá»‘t hÆ¡n 6,1%
- **Interpretation / Diá»…n giáº£i**: Explains 26% of variance / Giáº£i thÃ­ch 26% phÆ°Æ¡ng sai

### 10. Model Comparison (Cell 33) / So SÃ¡nh MÃ´ HÃ¬nh (Cell 33)
- Side-by-side metrics comparison / So sÃ¡nh chá»‰ sá»‘ song song
- Bar chart visualization / Trá»±c quan hÃ³a biá»ƒu Ä‘á»“ cá»™t
- **Winner / NgÆ°á»i Chiáº¿n Tháº¯ng**: XGBoost on all metrics / XGBoost á»Ÿ táº¥t cáº£ chá»‰ sá»‘

### 11. Feature Importance (Cell 34) / Äá»™ Quan Trá»ng Äáº·c TrÆ°ng (Cell 34)
- Extract importance from XGBoost / TrÃ­ch xuáº¥t Ä‘á»™ quan trá»ng tá»« XGBoost
- Top 5 predictors / 5 yáº¿u tá»‘ dá»± bÃ¡o hÃ ng Ä‘áº§u:
  1. lunch (34.2%)
  2. parental_education (21.5%)
  3. test_prep (18.9%)
  4. race/ethnicity (1.9%)
  5. gender (1.1%)
- Horizontal bar chart visualization / Trá»±c quan hÃ³a biá»ƒu Ä‘á»“ cá»™t ngang

### 12. Conclusions (Cell 37) / Káº¿t Luáº­n (Cell 37)
- Summary of findings / TÃ³m táº¯t cÃ¡c phÃ¡t hiá»‡n
- Policy recommendations (3 tiers) / Khuyáº¿n nghá»‹ chÃ­nh sÃ¡ch (3 cáº¥p)
- Limitations and future work / Háº¡n cháº¿ vÃ  hÆ°á»›ng phÃ¡t triá»ƒn tÆ°Æ¡ng lai

---

## ğŸ”„ Execution Flow / Luá»“ng Thá»±c Thi

**Important / Quan Trá»ng**: Run cells in order (1â†’37) / Cháº¡y cÃ¡c cells theo thá»© tá»± (1â†’37)
- Variables depend on previous cells / CÃ¡c biáº¿n phá»¥ thuá»™c vÃ o cÃ¡c cells trÆ°á»›c Ä‘Ã³
- Don't skip or reorder / KhÃ´ng Ä‘Æ°á»£c bá» qua hoáº·c sáº¯p xáº¿p láº¡i

**Runtime / Thá»i Gian Cháº¡y**: ~30-45 seconds for full notebook / ~30-45 giÃ¢y cho toÃ n bá»™ notebook

**Output Types / Loáº¡i Äáº§u Ra**:
- Console: Statistics, metrics / Thá»‘ng kÃª, chá»‰ sá»‘
- Tables: DataFrames displayed / Báº£ng: DataFrames Ä‘Æ°á»£c hiá»ƒn thá»‹
- Charts: 5+ visualizations (EDA, comparison, importance) / Biá»ƒu Ä‘á»“: 5+ trá»±c quan hÃ³a (EDA, so sÃ¡nh, Ä‘á»™ quan trá»ng)
- Warnings: Safe to ignore (deprecations) / Cáº£nh bÃ¡o: An toÃ n Ä‘á»ƒ bá» qua (khÃ´ng dÃ¹ng ná»¯a)

---

## ğŸ’¾ Key Variables / CÃ¡c Biáº¿n ChÃ­nh

### After Preprocessing (Cell 21) / Sau Tiá»n Xá»­ LÃ½ (Cell 21)
- `X`: Features / Äáº·c trÆ°ng (1000 Ã— 11)
- `y`: Target / Biáº¿n má»¥c tiÃªu (1000,)
- `X_train`, `X_test`: Train/test split / Chia train/test (800/200)
- `y_train`, `y_test`: Target split / Chia biáº¿n má»¥c tiÃªu

### After Modeling (Cells 29, 32) / Sau MÃ´ HÃ¬nh HÃ³a (Cells 29, 32)
- `lr_model`: Linear Regression object / Äá»‘i tÆ°á»£ng Há»“i Quy Tuyáº¿n TÃ­nh
- `xgb_model`: XGBoost object / Äá»‘i tÆ°á»£ng XGBoost
- `y_pred_lr`, `y_pred_xgb`: Predictions / Dá»± Ä‘oÃ¡n
- `lr_metrics`, `xgb_metrics`: Results dictionaries / Tá»« Ä‘iá»ƒn káº¿t quáº£

### After Feature Importance (Cell 34) / Sau PhÃ¢n TÃ­ch Äá»™ Quan Trá»ng (Cell 34)
- `feature_importance`: DataFrame with rankings / DataFrame vá»›i xáº¿p háº¡ng

---

## ğŸ¨ Visualizations Generated / Trá»±c Quan HÃ³a ÄÆ°á»£c Táº¡o

1. **Histograms** (Cell 16) - Score distributions / PhÃ¢n phá»‘i Ä‘iá»ƒm
2. **Heatmap** (Cell 17) - Correlation matrix / Ma tráº­n tÆ°Æ¡ng quan
3. **Boxplots** (Cell 18) - Features vs math score / Äáº·c trÆ°ng vs Ä‘iá»ƒm toÃ¡n
4. **Bar chart** (Cell 33) - Model comparison / So sÃ¡nh mÃ´ hÃ¬nh
5. **Bar chart** (Cell 34) - Feature importance / Äá»™ quan trá»ng Ä‘áº·c trÆ°ng

---

## ğŸ› ï¸ Useful Code Snippets / CÃ¡c Äoáº¡n MÃ£ Há»¯u Ãch

### Get metrics / Láº¥y chá»‰ sá»‘
```python
print(f"XGBoost RÂ²: {xgb_metrics['R2']:.4f}")
print(f"RMSE: {xgb_metrics['RMSE']:.2f}")
```

### Top features / CÃ¡c Ä‘áº·c trÆ°ng hÃ ng Ä‘áº§u
```python
print(feature_importance.head(3))
```

### Make prediction / ÄÆ°a ra dá»± Ä‘oÃ¡n
```python
new_data = X_test.iloc[[0]]
pred = xgb_model.predict(new_data)
```

### Save model / LÆ°u mÃ´ hÃ¬nh
```python
import joblib
joblib.dump(xgb_model, 'model.pkl')
```

---

## âš ï¸ Important Notes / CÃ¡c Ghi ChÃº Quan Trá»ng

**Data / Dá»¯ Liá»‡u**:
- Never modify original CSV / KhÃ´ng bao giá» sá»­a Ä‘á»•i CSV gá»‘c
- All transformations in notebook / Táº¥t cáº£ cÃ¡c biáº¿n Ä‘á»•i trong notebook
- Safe to re-run anytime / An toÃ n Ä‘á»ƒ cháº¡y láº¡i báº¥t ká»³ lÃºc nÃ o

**Reproducibility / TÃ¡i Láº­p**:
- `random_state=42` everywhere / `random_state=42` á»Ÿ má»i nÆ¡i
- Same results on re-runs / Káº¿t quáº£ giá»‘ng nhau khi cháº¡y láº¡i
- Notebook is deterministic / Notebook lÃ  xÃ¡c Ä‘á»‹nh

**Dependencies / ThÆ° Viá»‡n Phá»¥ Thuá»™c**:
- Requires `requirements.txt` packages / YÃªu cáº§u cÃ¡c gÃ³i trong `requirements.txt`
- Python 3.8-3.10 recommended / Python 3.8-3.10 Ä‘Æ°á»£c khuyáº¿n cÃ¡o
- 2GB RAM minimum / Tá»‘i thiá»ƒu 2GB RAM

---

## â“ Troubleshooting / Kháº¯c Phá»¥c Sá»± Cá»‘

| Problem / Váº¥n Äá» | Solution / Giáº£i PhÃ¡p |
|--------|----------|
| Module not found / KhÃ´ng tÃ¬m tháº¥y mÃ´-Ä‘un | Run cell 4 again, check requirements / Cháº¡y cell 4 láº¡i, kiá»ƒm tra requirements |
| Data not loading / Dá»¯ liá»‡u khÃ´ng táº£i | Verify CSV in SOURCE/ folder / XÃ¡c minh CSV trong thÆ° má»¥c SOURCE/ |
| Charts not showing / Biá»ƒu Ä‘á»“ khÃ´ng hiá»ƒn thá»‹ | Run `%matplotlib inline` in cell 4 / Cháº¡y `%matplotlib inline` trong cell 4 |
| Memory error / Lá»—i bá»™ nhá»› | Restart kernel, check system RAM / Khá»Ÿi Ä‘á»™ng láº¡i kernel, kiá»ƒm tra RAM há»‡ thá»‘ng |

---

**Version / PhiÃªn Báº£n**: 1.0  
**Last Updated / Cáº­p Nháº­t Láº§n Cuá»‘i**: November 2025 / ThÃ¡ng 11 nÄƒm 2025  
**Status / Tráº¡ng ThÃ¡i**: âœ… Production Ready / Sáºµn SÃ ng Sáº£n Xuáº¥t  
**Author / TÃ¡c Giáº£**: BÃ¹i Quang Chiáº¿n
